#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/mySummary.R")
#S data
load(file="input/Exp3_Survey.RData")
#general demographics
Age <- mySummary(S3, LAge)
range <- S3 %>% summarise(range(LAge))
sex <- table(S3$LSex)
language <- table(S3$LMotherLanguage)
LStudyWork <- table(S3$LStudyWork)
LHearingKown <- table(S3$LHearingKown)
LHearingKind <- table(S3$LHearingKind)
LHearingImp <- table(S3$LHearingImp)
duration <- S3 %>% summarise(Tmean = mean(TIME_total, na.rm= TRUE),
min = min(TIME_total, na.rm= TRUE),
max = max(TIME_total, na.rm= TRUE))
capture.output(as.matrix(Age), as.matrix(range), sex, language,
LStudyWork, LHearingKown, LHearingKind, LHearingImp, as.matrix(duration),
file="output/Exp3_demographics.txt")
rm(Age, range, sex, language, LStudyWork, LHearingKown, LHearingKind, LHearingImp, duration)
## comments
write.csv(data.frame(S3$participant, S3$VPN_Code, S3$Anmerkungen, S3$InstructionsClear, S3$Strategy), file="output/Exp3_comments.txt")
# after Exp-Evaluation
Eval1 <- table(S3$Eval1)
Eval2 <- table(S3$Eval2)
Eval3 <- table(S3$Eval3)
Eval4 <- table(S3$Eval4)
Eval5 <- table(S3$Eval5)
Eval6 <- table(S3$Eval6)
Eval7 <- table(S3$Eval7)
Eval8 <- table(S3$Eval8)
label <- c("Im Alltag achte ich stets auf den Klang der Stimme einer Person.",
"Es fiel mir äußerst schwer, die Stimmen zu bewerten.",
"Bei den meisten Stimmen hatte ich gar keine Ahnung, was ich dr?cken sollte.",
"Ich habe die ganze Zeit aufmerksam zugehört.",
"Oft habe ich einfach irgendetwas geklickt.",
"Ich fand dieses Hörexperiment äußerst interessant.",
"Ich habe in jedem Durchgang versucht, die Bewertung so gut wie möglich zu machen.",
"Ich achte normalerweise gar nicht auf die Stimmen von Personen.")
capture.output(label[1], Eval1, label[2],Eval2, label[3],Eval3,label[4], Eval4, label[5],Eval5, label[6], Eval6,label[7], Eval7, label[8], Eval8,file="output/Exp3_after_experiment_evaluation.txt")
rm(label, Eval1, Eval2, Eval3, Eval4, Eval5, Eval6, Eval7, Eval8)
View(S3)
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/mySummary.R")
#S data
load(file="input/Exp3_Survey.RData")
#general demographics
Age <- mySummary(S3, LAge)
range <- S3 %>% summarise(range(LAge))
sex <- table(S3$LSex)
language <- table(S3$LMotherLanguage)
LStudyWork <- table(S3$LStudyWork)
LHearingKown <- table(S3$LHearingKown)
LHearingKind <- table(S3$LHearingKind)
LHearingImp <- table(S3$LHearingImp)
duration <- S3 %>% summarise(Tmean = mean(TIME_total, na.rm= TRUE),
min = min(TIME_total, na.rm= TRUE),
max = max(TIME_total, na.rm= TRUE))
capture.output(as.matrix(Age), as.matrix(range), sex, language,
LStudyWork, LHearingKown, LHearingKind, LHearingImp, as.matrix(duration),
file="output/Exp3_demographics.txt")
rm(Age, range, sex, language, LStudyWork, LHearingKown, LHearingKind, LHearingImp, duration)
## comments
write.csv(data.frame(S3$participant, S3$VPN_Code, S3$Anmerkungen, S3$InstructionsClear, S3$Strategy), file="output/Exp3_comments.txt")
# after Exp-Evaluation
Eval1 <- table(S3$Eval1)
Eval2 <- table(S3$Eval2)
Eval3 <- table(S3$Eval3)
Eval4 <- table(S3$Eval4)
Eval5 <- table(S3$Eval5)
Eval6 <- table(S3$Eval6)
Eval7 <- table(S3$Eval7)
Eval8 <- table(S3$Eval8)
label <- c("Im Alltag achte ich stets auf den Klang der Stimme einer Person.",
"Es fiel mir äußerst schwer, die Stimmen zu bewerten.",
"Bei den meisten Stimmen hatte ich gar keine Ahnung, was ich dr?cken sollte.",
"Ich habe die ganze Zeit aufmerksam zugehört.",
"Oft habe ich einfach irgendetwas geklickt.",
"Ich fand dieses Hörexperiment äußerst interessant.",
"Ich habe in jedem Durchgang versucht, die Bewertung so gut wie möglich zu machen.",
"Ich achte normalerweise gar nicht auf die Stimmen von Personen.")
capture.output(label[1], Eval1, label[2],Eval2, label[3],Eval3,label[4], Eval4, label[5],Eval5, label[6], Eval6,label[7], Eval7, label[8], Eval8,file="output/Exp3_after_experiment_evaluation.txt")
rm(label, Eval1, Eval2, Eval3, Eval4, Eval5, Eval6, Eval7, Eval8)
#load the preprocessed raw data
load(file ="input/Exp3_raw_data.RData")
#check for the number of missing (indicated by RT == 3000)
missings_Adapt <-E3_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/224)
missings_Bline <- E3_Bline %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/112)
View(missings_Adapt)
View(E3_Bline)
View(missings_Bline)
##########################################################################
## File: 00_Exp3_data_preparation.R
## Data Preparation for Exp 2: Adaptation of Emotion - pseudowords
# author: Christine Nussbaum
# date 03/2025
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/loadPTKExperimentData.R")
source("functions/mySummary.R")
#---------------------------------------------------------------------------------
#get the raw data:
D <- loadPTKExperimentData(relDirPath = "input/raw/")
#number of participants
print(paste("There are currently", length(unique(D$Subject)), "participants loaded."))
#reorder columns - Subject Variablen zuerst
D <- D[,c(17,16,15, 1:14)]
#---------------------------------------------------------------------------------
#Data preparation
#[1] Split the data in the Baseline and the Adaptation-Block
E3_Bline <- D[,-c(12:17)] %>% filter(V1 == "Baseline")
E3_Adapt <- D %>% filter(V1 == "Antwort")
#[2] Rename Variables
names(E3_Bline) <- c("Participant", "Date", "Experiment","Block", "Duration", "SpID", "Word", "tML", "SpSex", "Resp","RT" )
names(E3_Adapt) <- c("Participant", "Date", "Experiment", "Block", "Duration", "SpID", "Word", "tML", "SpSex", "Resp", "RT", "AdaptType", "Blockorder", "TopUp", "z", "TopupM", "TopupF")
#[3] Adjust some settings of variables
E3_Bline$Resp <- as.numeric(E3_Bline$Resp)
E3_Adapt$Resp <- as.numeric(E3_Adapt$Resp)
#sort out all the counting variables responsible for the top-up E3_Adaptation:
E3_Adapt$z <- ifelse(E3_Adapt$TopUp != 0, NA, E3_Adapt$z)
E3_Adapt$TopupM <- ifelse(E3_Adapt$TopUp != 0, NA, E3_Adapt$TopupM)
E3_Adapt$TopupF <- ifelse(E3_Adapt$TopUp != 0, NA, E3_Adapt$TopupF)
E3_Adapt$TopUp <- ifelse(E3_Adapt$TopUp == 0, "Yes", NA) #Code if this was a TopUp Trial
#recode the Response for both datasets
E3_Bline$Resp <- E3_Bline$Resp -1 # umkodieren
E3_Adapt$Resp <- E3_Adapt$Resp -1 # umkodieren
#recode AdaptType
E3_Adapt$AdaptType <- recode(E3_Adapt$AdaptType,
"pw12_angry/pw35_fearful" = "pw12_ang/pw34_fea",
"pw35_angry/pw12_fearful" = "pw12_fea/pw34_ang")
#---------------------------------------------------------------------------------
#Check if everything is loaded correctly
#[1] N different stimuli per participant
table(E3_Bline$Participant) #should be 112 per participant
table(E3_Adapt$Participant) #should be 224 per participant
#[2]Is every stimulus picked exactly once? - Baseline
#code a stimulus variable
E3_Bline$Stimulus <- str_c(E3_Bline$SpID, E3_Bline$Word, E3_Bline$tML, sep = "_")
table(table(E3_Bline$Stimulus, E3_Bline$Participant)) #should give out only "1"s
#[3]Is every stimulus picked exactly twice? - Adaptation
E3_Adapt$Stimulus <- str_c(E3_Adapt$SpID, E3_Adapt$Word, E3_Adapt$tML, sep = "_")
table(table(E3_Adapt$Stimulus, E3_Adapt$Participant)) #should give out only "2"s
#---------------------------------------------------------------------------------
#Check if some participants only pressed one key during a whole block
# if so -> remove
Check_Bline <- E3_Bline %>% group_by(Participant) %>% summarise(var = var(Resp)) # no one
Check_Adapt <- E3_Adapt %>% group_by(Participant) %>% summarise(var = var(Resp)) # no one
#"59095ef5" has too many missing and must be removed
E3_Adapt <- E3_Adapt %>% filter(Participant != "59095ef5")
E3_Bline <- E3_Bline %>% filter(Participant != "59095ef5")
rm(Check_Bline, Check_Adapt)
#---------------------------------------------------------------------------------
#Save datasets
save(E3_Bline, E3_Adapt, file ="input/Exp3_raw_data.RData")
rm(D)
##################################################################################
##################################################################################
##################################################################################
#---------------------------------------------------------------------------------
# survey data preparation
#load raw survey data
S3 <- read.csv(file ="input/data_Exp3.csv")
#rename participant
S3$participant <- substr(S3$participant, 31,38)
#keep only the ones with an experimental file
S3 <- S3 %>% filter(participant %in% unique(E3_Adapt$Participant)) # check: N = 48
S3$VPN_Code <- paste0(S3$LPartCode_1, S3$LPartCode_2, S3$LPartCode_3, S3$LPartCode_4, S3$LPartCode_5, S3$LPartCode_6)
#rename a few variables
S3 <- S3 %>% select(!c(intro_question1_1,
TIME_start,
TIME_end,
CLIENT_start,
LPartCode_1,
LPartCode_2,
LPartCode_3,
LPartCode_4,
LPartCode_5,
LPartCode_6,
StartRatingExperiment_1)) %>%
rename(LAge = LAge_1,
LSex = LSex_1,
LMotherLanguage = LMotherLanguage_1,
LStudyWork = LStudyWork_1,
LHearingKown = LHearingDisabilitiesKnown_1,
LHearingKind = LHearingDisabilitiesKind_1,
LHearingImp = LHearingDisabilitiesConstraint_1,
Anmerkungen = Anmerkungen_1,
InstructionsClear = afterExp2InstructionsClear_1,
Strategy = afterExp4Strategy_1,
Eval1 = afterExp3RatingEvaluation_1,
Eval2 = afterExp3RatingEvaluation_2,
Eval3 = afterExp3RatingEvaluation_3,
Eval4 = afterExp3RatingEvaluation_4,
Eval5 = afterExp3RatingEvaluation_5,
Eval6 = afterExp3RatingEvaluation_6,
Eval7 = afterExp3RatingEvaluation_7,
Eval8 = afterExp3RatingEvaluation_8)
#save survey
save(S3, file="input/Exp3_survey.RData")
##End of Script
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/mySummary.R")
#---------------------------------------------------------------------------------
#get the preprocessed data:
#S data
load(file="input/Exp3_Survey.RData")
## Meaning of Variables
#ToDo
#------------------------------------------------------------------------------------------------------------------#
#                                           Sample Demographics                                                    #
#------------------------------------------------------------------------------------------------------------------#
#general demographics
Age <- mySummary(S3, LAge)
range <- S3 %>% summarise(range(LAge))
sex <- table(S3$LSex)
language <- table(S3$LMotherLanguage)
LStudyWork <- table(S3$LStudyWork)
LHearingKown <- table(S3$LHearingKown)
LHearingKind <- table(S3$LHearingKind)
LHearingImp <- table(S3$LHearingImp)
duration <- S3 %>% summarise(Tmean = mean(TIME_total, na.rm= TRUE),
min = min(TIME_total, na.rm= TRUE),
max = max(TIME_total, na.rm= TRUE))
capture.output(as.matrix(Age), as.matrix(range), sex, language,
LStudyWork, LHearingKown, LHearingKind, LHearingImp, as.matrix(duration),
file="output/Exp3_demographics.txt")
rm(Age, range, sex, language, LStudyWork, LHearingKown, LHearingKind, LHearingImp, duration)
## comments
write.csv(data.frame(S3$participant, S3$VPN_Code, S3$Anmerkungen, S3$InstructionsClear, S3$Strategy), file="output/Exp3_comments.txt")
# after Exp-Evaluation
Eval1 <- table(S3$Eval1)
Eval2 <- table(S3$Eval2)
Eval3 <- table(S3$Eval3)
Eval4 <- table(S3$Eval4)
Eval5 <- table(S3$Eval5)
Eval6 <- table(S3$Eval6)
Eval7 <- table(S3$Eval7)
Eval8 <- table(S3$Eval8)
label <- c("Im Alltag achte ich stets auf den Klang der Stimme einer Person.",
"Es fiel mir äußerst schwer, die Stimmen zu bewerten.",
"Bei den meisten Stimmen hatte ich gar keine Ahnung, was ich dr?cken sollte.",
"Ich habe die ganze Zeit aufmerksam zugehört.",
"Oft habe ich einfach irgendetwas geklickt.",
"Ich fand dieses Hörexperiment äußerst interessant.",
"Ich habe in jedem Durchgang versucht, die Bewertung so gut wie möglich zu machen.",
"Ich achte normalerweise gar nicht auf die Stimmen von Personen.")
capture.output(label[1], Eval1, label[2],Eval2, label[3],Eval3,label[4], Eval4, label[5],Eval5, label[6], Eval6,label[7], Eval7, label[8], Eval8,file="output/Exp3_after_experiment_evaluation.txt")
rm(label, Eval1, Eval2, Eval3, Eval4, Eval5, Eval6, Eval7, Eval8)
#load the preprocessed raw data
load(file ="input/Exp3_raw_data.RData")
#check for the number of missing (indicated by RT == 3000)
missings_Adapt <-E3_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/224)
missings_Bline <- E3_Bline %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/112)
View(missings_Adapt)
View(E3_Bline)
View(missings_Bline)
sum(missing_Adapt$N)
sum(missings_Adapt$N)
sum(missings_Bline$N)
View(E3_Bline)
View(missings_Bline)
#remove omissions from the data
E3_Adapt <- E3_Adapt %>% filter(RT != 3000) # 45 removed
E3_Bline <- E3_Bline %>% filter(RT != 3000) # 65 removed
rm(missings_Bline, missings_Adapt)
#save datasets again
save(E3_Bline, E3_Adapt, file ="input/Exp3_without_omissions.RData")
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
library("ez")
library("effectsize")
# load relevant functions
source("functions/mySummary.R")
source("functions/fitCumulativeGaussian.R")
load(file ="input/Exp3_without_omissions.RData")
#code Pseudowords into groups
E3_Adapt$PW_Group <- NA
View(E3_Adapt)
#code Pseudowords into groups
E3_Adapt$PW_Group <- ifelse(E3_Adapt$Word == "w01" | E3_Adapt$Word == "w02", "pw12", "pw34")
table(E3_Adapt$PW_Group, E3_Adapt$Word)
##################################################################
##average data across SpeakerID (for Adaptation and Baseline block individually, and them combine the two)
CG_input <- mySummary(E3_Adapt, Resp, Participant, AdaptType, PW_Group, SpSex, tML) # Input for each participant, Adaptation Blocks
CG_input_BL <- mySummary(E3_Bline, Resp, Participant, Block, SpSex, SpID, tML) # Input for each participant, Baseline Blocks
CG_input <- mySummary(E3_Adapt, Resp, Participant, AdaptType, PW_Group, SpSex, tML) # Input for each participant, Adaptation Blocks
CG_input_BL <- mySummary(E3_Bline, Resp, Participant, Block, SpSex, PW_Group, tML) # Input for each participant, Baseline Blocks
E3_Bline$PW_Group <- ifelse(E3_Bline$Word == "w01" | E3_Bline$Word == "w02", "pw12", "pw34")
##################################################################
##average data across SpeakerID (for Adaptation and Baseline block individually, and them combine the two)
CG_input <- mySummary(E3_Adapt, Resp, Participant, AdaptType, PW_Group, SpSex, tML) # Input for each participant, Adaptation Blocks
CG_input_BL <- mySummary(E3_Bline, Resp, Participant, Block, SpSex, PW_Group, tML) # Input for each participant, Baseline Blocks
CG_input_BL <- CG_input_BL %>% rename(AdaptType= Block)
CG_input <- rbind(CG_input, CG_input_BL)
rm(CG_input_BL)
47*2*3*2*7
## declare tML as numerical variable
CG_input$tML <- as.numeric(as.character(CG_input$tML))
#Fit a Cumulative Gaussian Function (CG) for each Subject x SpSex * AdaptType
CGdata <- myCGfit(CG_input, x = unique(CG_input$tML), Resp, Participant, AdaptType, SpID, SpSex)
#Fit a Cumulative Gaussian Function (CG) for each Subject x SpSex * AdaptType
CGdata <- myCGfit(CG_input, x = unique(CG_input$tML), Resp, Participant, AdaptType, PW_Group, SpSex)
### There were 1962 warnings -> this happens when the algorithm tried to fit numbers that create a NaN in the pnorm()-command
warnings()
47*2*3*2
##################################################################
## plot values of the fits to identify outlier
summary(CGdata[,4:6]) # yep... some fits went wrong
#PSE - point of subjective equality
dotchart(CGdata$PSE)
hist(CGdata$PSE)
boxplot(CGdata$PSE)
#R2 - fit of the function
dotchart(CGdata$R2)
hist(CGdata$R2)
boxplot(CGdata$R2)
# inspect subjects that have a PSE > 100 and 0
badFit <- CGdata %>% filter(PSE > 100 | PSE < 0)
unique(badFit$Participant) # 15 Subjects have bad fits and should be excluded in a second analysis
rm(badFitR2, badFitPSE)
###remove 6 participants with bad fit
CGdata <- CGdata %>% filter(!(Participant %in% badFit$Participant))
41*2*3*1
41*2*3*2
# now check again PSE values and R2
dotchart(CGdata$PSE) # all beautiful
dotchart(CGdata$R2)  # really not ideal
##create a new input variable, because we just have N=28 now
CG_input <- CG_input %>% filter(!(Participant %in% badFit$Participant))
CG_agg_input <- mySummary(CG_input, Resp, AdaptType, SpSex, SpID, tML) # Input averaged across all participant
## declare tML as numerical variable
CG_agg_input$tML <- as.numeric(as.character(CG_agg_input$tML))
##create a new input variable, because we just have N=28 now
CG_input <- CG_input %>% filter(!(Participant %in% badFit$Participant))
CG_agg_input <- mySummary(CG_input, Resp, AdaptType, SpSex, PW_Word, tML) # Input averaged across all participant
View(CG_input)
CG_agg_input <- mySummary(CG_input, Resp, AdaptType, SpSex, PW_Group, tML) # Input averaged across all participant
## declare tML as numerical variable
CG_agg_input$tML <- as.numeric(as.character(CG_agg_input$tML))
#estimate the averaged cumulative gaussian
CGagg <- myCGfit(CG_agg_input, x = unique(CG_agg_input$tML), Resp, AdaptType, SpID, SpSex)
View(CGdata)
#estimate the averaged cumulative gaussian
CGagg <- myCGfit(CG_agg_input, x = unique(CG_agg_input$tML), Resp, AdaptType, PW_Group, SpSex)
View(CGagg)
#save the datasets
save(CGagg, CGdata, CG_input, CG_agg_input, badFit, file="input/Exp3_CG_estimates.RData")
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
library("ez")
library("effectsize")
library(lme4)           # version 1.1-35.1
library(ggeffects)      # version 1.6.0
library(afex)           # version 1.3-1
# load relevant functions
source("functions/mySummary.R")
source("functions/tracedEzOut.R")
load(file ="input/Exp3_without_omissions.RData")
load(file ="input/Exp3_CG_estimates.RData")
#remove that we dont need for the analysis
rm(badFit, CG_agg_input, CG_input, CG_agg) # we just need CG_data
#remove that we dont need for the analysis
rm(badFit, CG_agg_input, CG_input, CG_agg, CGagg) # we just need CGdata
#remove Baseline for data analysis
CGdata_Adapt <- CGdata %>% filter(AdaptType != "Baseline")
a<-ezANOVA(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, PW_Word, SpSex), type=3, detailed = TRUE)
View(CGdata_Adapt)
a<-ezANOVA(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, PW_Group, SpSex), type=3, detailed = TRUE)
b = tracedEzOut(a, print = TRUE, sph.cor = "HF", mau.p = 0.05, etasq = "partial", dfsep = ", ")
capture.output(b, file= "output/Exp3_CG_ANOVAI.txt")
# visualize data (just to check)
ezPlot(data=CGdata_Adapt_f, dv=.(PSE), wid=.(Participant), within = .(AdaptType, PW_Group), x=PW_Group, split=AdaptType)
#aggregate Data (in this case not really necessary)
PH1 <- CGdata_Adapt_f %>% group_by(Participant, SpID, AdaptType) %>% summarise(PSE = mean(PSE))
# visualize data (just to check)
ezPlot(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, PW_Group), x=PW_Group, split=AdaptType)
load(file ="input/Exp3_CG_estimates.RData")
View(CGagg)
##########################################################################
## File: 03_Exp3_data_analysis.R
## Data Analysis for Exp 3: Adaptation of Emotion - pseudowords
# author: Christine Nussbaum
# date 03/2025
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
library("ez")
library("effectsize")
library(lme4)           # version 1.1-35.1
library(ggeffects)      # version 1.6.0
library(afex)           # version 1.3-1
#library("ggplot2")
# load relevant functions
source("functions/mySummary.R")
source("functions/tracedEzOut.R")
#---------------------------------------------------------------------------------
#get the CG input data:
load(file ="input/Exp3_without_omissions.RData")
load(file ="input/Exp3_CG_estimates.RData")
#remove that we dont need for the analysis
rm(badFit, CG_agg_input, CG_input, CG_agg, CGagg) # we just need CGdata
#-------------------------------------------------------------------------------#
#                      Analysis 1: Via Cumulative Gaussians                     #
#-------------------------------------------------------------------------------#
#remove Baseline for data analysis
CGdata_Adapt <- CGdata %>% filter(AdaptType != "Baseline")
##########################################################################
## ANOVA I: 2 x 2 x 2  within subject
# data: CGdata_Adapt (without Baseline)
# dv: PSE
# wid: Participant
# within: AdaptType, PW_Group, SpSex
a<-ezANOVA(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, PW_Group, SpSex), type=3, detailed = TRUE)
b = tracedEzOut(a, print = TRUE, sph.cor = "HF", mau.p = 0.05, etasq = "partial", dfsep = ", ")
#N= 41 entered Analysis
##############################################################################
#Output                                     Text
# 1              (Intercept) F(1,40) = 2924.298, p < .001, np2 = .987
# 2                AdaptType F(1,40) =    3.428, p = .071, np2 = .079
# 3                 PW_Group F(1,40) =   11.237, p = .002, np2 = .219
# 4                    SpSex F(1,40) =    0.005, p = .946, np2 < .010
# 5       AdaptType:PW_Group F(1,40) =    3.156, p = .083, np2 = .073
# 6          AdaptType:SpSex F(1,40) =    2.761, p = .104, np2 = .065
# 7           PW_Group:SpSex F(1,40) =   26.383, p < .001, np2 = .397
# 8 AdaptType:PW_Group:SpSex F(1,40) =    0.021, p = .886, np2 < .011
##############################################################################
capture.output(b, file= "output/Exp3_CG_ANOVAI.txt")
# visualize data (just to check)
ezPlot(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, PW_Group), x=PW_Group, split=AdaptType)
#this suggests an effect but I am very suspicious!
#this suggests an effect but I am very suspicious!
rm(a,b, CG_data, CG_data_Adapt)
View(E3_Adapt)
#aggregate across pseudoword, speaker and tML for analysis
E3_Resp <- mySummary(E3_Adapt, Resp, Participant, Word, SpSex, AdaptType) #does not contain Baseline
a<-ezANOVA(data=E3_Resp_f, dv=.(Resp), wid=.(Participant), within = .(AdaptType, SpSex, Word), type=3, detailed = TRUE)
a<-ezANOVA(data=E3_Resp, dv=.(Resp), wid=.(Participant), within = .(AdaptType, SpSex, Word), type=3, detailed = TRUE)
b = tracedEzOut(a, print = TRUE, sph.cor = "HF", mau.p = 0.05, etasq = "partial", dfsep = ", ")
# visualize data (just to check)
ezPlot(data=E3_Resp, dv=.(Resp), wid=.(Participant), within = .(AdaptType, Word), x=Word, split=AdaptType)
# visualize data (just to check)
ezPlot(data=E3_Resp, dv=.(Resp), wid=.(Participant), within = .(AdaptType, Word), split=Word, x=AdaptType)
#-------------------------------------------------------------------------------#
#                        Analysis 3: logistic regression                        #
#-------------------------------------------------------------------------------#
## declare tML as numerical variable
E3_Adapt$tML <- as.numeric(as.character(E3_Adapt$tML))
#scale tML, because this is recommended for mixed-effects modelling
E3_Adapt$tML_sc <- scale(E3_Adapt$tML)
# m: assumed fixed effects structure for Participant
m <- glmer(Resp ~ tML_sc * Word * AdaptType * SpSex + (1 | SpID)   + (1 | Participant), data = E3_Adapt_f, family = binomial,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))) # it was recommended to try out different optimizers to avoid converging failure and this worked
#------------------------------------------------------------------------
# Step2: calculating the p-values of the effects with afex
m_test<- mixed(m, data = E3_Adapt_f, method = "LRT", family = "binomial") # takes a few minutes
# m: assumed fixed effects structure for Participant
m <- glmer(Resp ~ tML_sc * Word * AdaptType * SpSex + (1 | SpID)   + (1 | Participant), data = E3_Adapt, family = binomial,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))) # it was recommended to try out different optimizers to avoid converging failure and this worked
#------------------------------------------------------------------------
# Step2: calculating the p-values of the effects with afex
m_test<- mixed(m, data = E3_Adapt, method = "LRT", family = "binomial") # takes a few minutes
m_test
summary(m)
# save models as R objects
save(m, m_test, file= "input/E3_GLMs.RData")
# capture output of model "m"
capture.output(summary(m), m_test, file= "output/Exp3_GLMM.txt")
# extract fitted values
E3_Adapt$fitted <- fitted(m)
#aggregate values of fitted
GLM_fit <- mySummary(E3_Adapt, fitted, Participant, SpID, AdaptType)
#aggregate values of fitted
GLM_fit <- mySummary(E3_Adapt, fitted, Participant, Word, AdaptType)
GLM_descriptive <- mySummary(GLM_fit, fitted, Word, AdaptType)
View(GLM_descriptive)
capture.output(GLM_descriptive, file= "output/Exp3_GLMM_female_descriptive.txt")
