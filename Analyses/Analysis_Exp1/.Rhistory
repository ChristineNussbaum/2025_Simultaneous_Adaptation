#---------------------------------------------------------------------------------
#get the raw data:
D <- loadPTKExperimentData(relDirPath = "input/raw/")
#number of participants
print(paste("There are currently", length(unique(D$Subject)), "participants loaded."))
#reorder columns - Subject Variablen zuerst
D <- D[,c(17,16,15, 1:14)]
#---------------------------------------------------------------------------------
#Data preparation
#[1] Split the data in the Baseline and the Adaptation-Block
E2_Bline <- D[,-c(12:17)] %>% filter(V1 == "Baseline")
E2_Adapt <- D %>% filter(V1 == "Antwort")
#[2] Rename Variables
names(E2_Bline) <- c("Participant", "Date", "Experiment","Block", "Duration", "SpID", "Word", "tML", "SpSex", "Resp","RT" )
names(E2_Adapt) <- c("Participant", "Date", "Experiment", "Block", "Duration", "SpID", "Word", "tML", "SpSex", "Resp", "RT", "AdaptType", "Blockorder", "TopUp", "z", "TopupM", "TopupF")
#[3] Adjust some settings of variables
E2_Bline$Resp <- as.numeric(E2_Bline$Resp)
E2_Adapt$Resp <- as.numeric(E2_Adapt$Resp)
#sort out all the counting variables responsible for the top-up E2_Adaptation:
E2_Adapt$z <- ifelse(E2_Adapt$TopUp != 0, NA, E2_Adapt$z)
E2_Adapt$TopupM <- ifelse(E2_Adapt$TopUp != 0, NA, E2_Adapt$TopupM)
E2_Adapt$TopupF <- ifelse(E2_Adapt$TopUp != 0, NA, E2_Adapt$TopupF)
E2_Adapt$TopUp <- ifelse(E2_Adapt$TopUp == 0, "Yes", NA) #Code if this was a TopUp Trial
#recode the Response for both datasets
E2_Bline$Resp <- E2_Bline$Resp -1 # umkodieren
E2_Adapt$Resp <- E2_Adapt$Resp -1 # umkodieren
#recode AdaptType
E2_Adapt$AdaptType <- recode(E2_Adapt$AdaptType,
"Identität1_angry/Identität3_fearful" = "f1_ang/f2_fea",
"Identität3_angry/Identität1_fearful" = "f1_fea/f2_ang",
"Identität3_angry/Identität4_fearful" = "m3_ang/m4_fea",
"Identität4_angry/Identität3_fearful" = "m3_fea/m4_ang")
#---------------------------------------------------------------------------------
#Check if everything is loaded correctly
#[1] N different stimuli per participant
table(E2_Bline$Participant) #should be 112 per participant
table(E2_Adapt$Participant) #should be 224 per participant
#[2]Is every stimulus picked exactly once? - Baseline
#code a stimulus variable
E2_Bline$Stimulus <- str_c(E2_Bline$SpID, E2_Bline$Word, E2_Bline$tML, sep = "_")
table(table(E2_Bline$Stimulus, E2_Bline$Participant)) #should give out only "1"s
#[3]Is every stimulus picked exactly twice? - Adaptation
E2_Adapt$Stimulus <- str_c(E2_Adapt$SpID, E2_Adapt$Word, E2_Adapt$tML, sep = "_")
table(table(E2_Adapt$Stimulus, E2_Adapt$Participant)) #should give out only "2"s
View(E2_Adapt)
Check_Bline <- E2_Bline %>% group_by(Participant) %>% summarise(var = var(Resp)) # no one
Check_Adapt <- E2_Adapt %>% group_by(Participant) %>% summarise(var = var(Resp)) # no one
View(Check_Bline)
#"dd1685a2f" pressed only one key, so will be removed
E2_Adapt <- E2_Adapt %>% filter(Participant != "d1685a2f")
E2_Bline <- E2_Bline %>% filter(Participant != "d1685a2f")
rm(Check_Bline, Check_Adapt)
rm(Check_Bline, Check_Adapt)
#---------------------------------------------------------------------------------
#Save datasets
save(E2_Bline, E2_Adapt, file ="input/Exp2_raw_data.RData")
rm(D)
#load raw survey data
S1 <- read.csv(file ="input/data_Exp2.csv")
#rename participant
S1$participant <- substr(S1$participant, 31,38)
#keep only the ones with an experimental file
S1 <- S1 %>% filter(participant %in% unique(E2_Adapt$Participant)) # check: N = 40
S1$VPN_Code <- paste0(S1$LPartCode_1, S1$LPartCode_2, S1$LPartCode_3, S1$LPartCode_4, S1$LPartCode_5, S1$LPartCode_6)
View(S1)
#rename a few variables
S1 <- S1 %>% select(!c(intro_question1_1,
TIME_start,
TIME_end,
CLIENT_start,
LPartCode_1,
LPartCode_2,
LPartCode_3,
LPartCode_4,
LPartCode_5,
LPartCode_6,
StartRatingExperiment_1,
country)) %>%
rename(LAge = LAge_1,
LSex = LSex_1,
LMotherLanguage = LMotherLanguage_1,
LStudyWork = LStudyWork_1,
LHearingKown = LHearingDisabilitiesKnown_1,
LHearingKind = LHearingDisabilitiesKind_1,
LHearingImp = LHearingDisabilitiesConstraint_1,
Anmerkungen = Anmerkungen_1,
InstructionsClear = afterExp2InstructionsClear_1,
Strategy = afterExp4Strategy_1,
Eval1 = afterExp3RatingEvaluation_1,
Eval2 = afterExp3RatingEvaluation_2,
Eval3 = afterExp3RatingEvaluation_3,
Eval4 = afterExp3RatingEvaluation_4,
Eval5 = afterExp3RatingEvaluation_5,
Eval6 = afterExp3RatingEvaluation_6,
Eval7 = afterExp3RatingEvaluation_7,
Eval8 = afterExp3RatingEvaluation_8)
View(S1)
S1 <- S1 %>% select(!c(intro_question1_1,
TIME_start,
TIME_end,
CLIENT_start,
LPartCode_1,
LPartCode_2,
LPartCode_3,
LPartCode_4,
LPartCode_5,
LPartCode_6,
StartRatingExperiment_1)) %>%
rename(LAge = LAge_1,
LSex = LSex_1,
LMotherLanguage = LMotherLanguage_1,
LStudyWork = LStudyWork_1,
LHearingKown = LHearingDisabilitiesKnown_1,
LHearingKind = LHearingDisabilitiesKind_1,
LHearingImp = LHearingDisabilitiesConstraint_1,
Anmerkungen = Anmerkungen_1,
InstructionsClear = afterExp2InstructionsClear_1,
Strategy = afterExp4Strategy_1,
Eval1 = afterExp3RatingEvaluation_1,
Eval2 = afterExp3RatingEvaluation_2,
Eval3 = afterExp3RatingEvaluation_3,
Eval4 = afterExp3RatingEvaluation_4,
Eval5 = afterExp3RatingEvaluation_5,
Eval6 = afterExp3RatingEvaluation_6,
Eval7 = afterExp3RatingEvaluation_7,
Eval8 = afterExp3RatingEvaluation_8)
View(S1)
#load raw survey data
S2 <- read.csv(file ="input/data_Exp2.csv")
#rename participant
S2$participant <- substr(S2$participant, 31,38)
#keep only the ones with an experimental file
S2 <- S2 %>% filter(participant %in% unique(E2_Adapt$Participant)) # check: N = 44
S2$VPN_Code <- paste0(S2$LPartCode_1, S2$LPartCode_2, S2$LPartCode_3, S2$LPartCode_4, S2$LPartCode_5, S2$LPartCode_6)
#rename a few variables
S2 <- S2 %>% select(!c(intro_question1_1,
TIME_start,
TIME_end,
CLIENT_start,
LPartCode_1,
LPartCode_2,
LPartCode_3,
LPartCode_4,
LPartCode_5,
LPartCode_6,
StartRatingExperiment_1)) %>%
rename(LAge = LAge_1,
LSex = LSex_1,
LMotherLanguage = LMotherLanguage_1,
LStudyWork = LStudyWork_1,
LHearingKown = LHearingDisabilitiesKnown_1,
LHearingKind = LHearingDisabilitiesKind_1,
LHearingImp = LHearingDisabilitiesConstraint_1,
Anmerkungen = Anmerkungen_1,
InstructionsClear = afterExp2InstructionsClear_1,
Strategy = afterExp4Strategy_1,
Eval1 = afterExp3RatingEvaluation_1,
Eval2 = afterExp3RatingEvaluation_2,
Eval3 = afterExp3RatingEvaluation_3,
Eval4 = afterExp3RatingEvaluation_4,
Eval5 = afterExp3RatingEvaluation_5,
Eval6 = afterExp3RatingEvaluation_6,
Eval7 = afterExp3RatingEvaluation_7,
Eval8 = afterExp3RatingEvaluation_8)
#save survey
save(S2, file="input/Exp2_survey.RData")
##End of S2cript
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/mySummary.R")
#S data
load(file="input/Exp2_Survey.RData")
#general demographics
Age <- mySummary(S1, LAge)
#general demographics
Age <- mySummary(S2, LAge)
range <- S2 %>% summarise(range(LAge))
sex <- table(S2$LSex)
language <- table(S2$LMotherLanguage)
LStudyWork <- table(S2$LStudyWork)
LHearingKown <- table(S2$LHearingKown)
LHearingKind <- table(S2$LHearingKind)
LHearingImp <- table(S2$LHearingImp)
duration <- S2 %>% summarise(Tmean = mean(TIME_total),
min = min(TIME_total),
max = max(TIME_total))
capture.output(as.matrix(Age), as.matrix(range), sex, language,
LStudyWork, LHearingKown, LHearingKind, LHearingImp, as.matrix(duration),
file="output/Exp1_demographics.txt")
rm(Age, range, sex, language, LStudyWork, LHearingKown, LHearingKind, LHearingImp, duration)
## comments
write.csv(data.frame(S2$participant, S2$VPN_Code, S2$Anmerkungen, S2$InstructionsClear, S2$Strategy), file="output/Exp1_comments.txt")
# after Exp-Evaluation
Eval1 <- table(S2$Eval1)
Eval2 <- table(S2$Eval2)
Eval3 <- table(S2$Eval3)
Eval4 <- table(S2$Eval4)
Eval5 <- table(S2$Eval5)
Eval6 <- table(S2$Eval6)
Eval7 <- table(S2$Eval7)
Eval8 <- table(S2$Eval8)
label <- c("Im Alltag achte ich stets auf den Klang der Stimme einer Person.",
"Es fiel mir äußerst schwer, die Stimmen zu bewerten.",
"Bei den meisten Stimmen hatte ich gar keine Ahnung, was ich dr?cken sollte.",
"Ich habe die ganze Zeit aufmerksam zugehört.",
"Oft habe ich einfach irgendetwas geklickt.",
"Ich fand dieses Hörexperiment äußerst interessant.",
"Ich habe in jedem Durchgang versucht, die Bewertung so gut wie möglich zu machen.",
"Ich achte normalerweise gar nicht auf die Stimmen von Personen.")
capture.output(label[1], Eval1, label[2],Eval2, label[3],Eval3,label[4], Eval4, label[5],Eval5, label[6], Eval6,label[7], Eval7, label[8], Eval8,file="output/Exp1_after_experiment_evaluation.txt")
rm(label, Eval1, Eval2, Eval3, Eval4, Eval5, Eval6, Eval7, Eval8)
## End of Script
View(S2)
#general demographics
Age <- mySummary(S2, LAge)
range <- S2 %>% summarise(range(LAge))
sex <- table(S2$LSex)
language <- table(S2$LMotherLanguage)
LStudyWork <- table(S2$LStudyWork)
LHearingKown <- table(S2$LHearingKown)
LHearingKind <- table(S2$LHearingKind)
LHearingImp <- table(S2$LHearingImp)
duration <- S2 %>% summarise(Tmean = mean(TIME_total, na.rm= TRUE),
min = min(TIME_total, na.rm= TRUE),
max = max(TIME_total, na.rm= TRUE))
capture.output(as.matrix(Age), as.matrix(range), sex, language,
LStudyWork, LHearingKown, LHearingKind, LHearingImp, as.matrix(duration),
file="output/Exp1_demographics.txt")
rm(Age, range, sex, language, LStudyWork, LHearingKown, LHearingKind, LHearingImp, duration)
## comments
write.csv(data.frame(S2$participant, S2$VPN_Code, S2$Anmerkungen, S2$InstructionsClear, S2$Strategy), file="output/Exp1_comments.txt")
# after Exp-Evaluation
Eval1 <- table(S2$Eval1)
Eval2 <- table(S2$Eval2)
Eval3 <- table(S2$Eval3)
Eval4 <- table(S2$Eval4)
Eval5 <- table(S2$Eval5)
Eval6 <- table(S2$Eval6)
Eval7 <- table(S2$Eval7)
Eval8 <- table(S2$Eval8)
label <- c("Im Alltag achte ich stets auf den Klang der Stimme einer Person.",
"Es fiel mir äußerst schwer, die Stimmen zu bewerten.",
"Bei den meisten Stimmen hatte ich gar keine Ahnung, was ich dr?cken sollte.",
"Ich habe die ganze Zeit aufmerksam zugehört.",
"Oft habe ich einfach irgendetwas geklickt.",
"Ich fand dieses Hörexperiment äußerst interessant.",
"Ich habe in jedem Durchgang versucht, die Bewertung so gut wie möglich zu machen.",
"Ich achte normalerweise gar nicht auf die Stimmen von Personen.")
capture.output(label[1], Eval1, label[2],Eval2, label[3],Eval3,label[4], Eval4, label[5],Eval5, label[6], Eval6,label[7], Eval7, label[8], Eval8,file="output/Exp1_after_experiment_evaluation.txt")
rm(label, Eval1, Eval2, Eval3, Eval4, Eval5, Eval6, Eval7, Eval8)
## End of Script
#general demographics
Age <- mySummary(S2, LAge)
range <- S2 %>% summarise(range(LAge))
sex <- table(S2$LSex)
language <- table(S2$LMotherLanguage)
LStudyWork <- table(S2$LStudyWork)
LHearingKown <- table(S2$LHearingKown)
LHearingKind <- table(S2$LHearingKind)
LHearingImp <- table(S2$LHearingImp)
duration <- S2 %>% summarise(Tmean = mean(TIME_total, na.rm= TRUE),
min = min(TIME_total, na.rm= TRUE),
max = max(TIME_total, na.rm= TRUE))
capture.output(as.matrix(Age), as.matrix(range), sex, language,
LStudyWork, LHearingKown, LHearingKind, LHearingImp, as.matrix(duration),
file="output/Exp2_demographics.txt")
rm(Age, range, sex, language, LStudyWork, LHearingKown, LHearingKind, LHearingImp, duration)
## comments
write.csv(data.frame(S2$participant, S2$VPN_Code, S2$Anmerkungen, S2$InstructionsClear, S2$Strategy), file="output/Exp2_comments.txt")
# after Exp-Evaluation
Eval1 <- table(S2$Eval1)
Eval2 <- table(S2$Eval2)
Eval3 <- table(S2$Eval3)
Eval4 <- table(S2$Eval4)
Eval5 <- table(S2$Eval5)
Eval6 <- table(S2$Eval6)
Eval7 <- table(S2$Eval7)
Eval8 <- table(S2$Eval8)
label <- c("Im Alltag achte ich stets auf den Klang der Stimme einer Person.",
"Es fiel mir äußerst schwer, die Stimmen zu bewerten.",
"Bei den meisten Stimmen hatte ich gar keine Ahnung, was ich dr?cken sollte.",
"Ich habe die ganze Zeit aufmerksam zugehört.",
"Oft habe ich einfach irgendetwas geklickt.",
"Ich fand dieses Hörexperiment äußerst interessant.",
"Ich habe in jedem Durchgang versucht, die Bewertung so gut wie möglich zu machen.",
"Ich achte normalerweise gar nicht auf die Stimmen von Personen.")
capture.output(label[1], Eval1, label[2],Eval2, label[3],Eval3,label[4], Eval4, label[5],Eval5, label[6], Eval6,label[7], Eval7, label[8], Eval8,file="output/Exp2_after_experiment_evaluation.txt")
rm(label, Eval1, Eval2, Eval3, Eval4, Eval5, Eval6, Eval7, Eval8)
## End of Script
View(S2)
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/mySummary.R")
#---------------------------------------------------------------------------------
#get the preprocessed data:
#S data
load(file="input/Exp1_Survey.RData")
rm(S1)
#load the preprocessed raw data
load(file ="input/Exp1_raw_data.RData")
#check for the number of missing (indicated by RT == 3000)
missings_Adapt <-E1_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant))
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
# load relevant functions
source("functions/mySummary.R")
#load the preprocessed raw data
load(file ="input/Exp1_raw_data.RData")
#check for the number of missing (indicated by RT == 3000)
missings_Adapt <-E1_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant))
View(missings_Adapt)
missings_Adapt <-E1_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/224)
View(missings_Adapt)
#check for the number of missing (indicated by RT == 3000)
missings_Adapt <-E1_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/224)
missings_Bline<-E1_Bline %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/112)
View(missings_Bline)
missings_Adapt <-E1_Adapt %>%  group_by(Participant) %>% summarise(N = length(RT == 3000),
prop = N/224)
View(missings_Adapt)
write.csv(missings_Adapt, missings_Bline, file = "putput/Exp1_omissions_summary.txt")
write.csv(missings_Adapt, missings_Bline, file = "output/Exp1_omissions_summary.txt")
capture.output(missings_Adapt, missings_Bline, file = "output/Exp1_omissions_summary.txt")
capture.output(as.matrix(missings_Adapt), as.Matrix(missings_Bline), file = "output/Exp1_omissions_summary.txt")
capture.output(as.matrix(missings_Adapt), as.matrix(missings_Bline), file = "output/Exp1_omissions_summary.txt")
#remove omissions from the data
E1_Adapt <- E1_Adapt %>% filter(RT == 3000) # 8960
#load the preprocessed raw data
load(file ="input/Exp1_raw_data.RData")
#check for the number of missing (indicated by RT == 3000)
missings_Adapt <-E1_Adapt %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/224)
missings_Bline <- E1_Bline %>%  group_by(Participant) %>% filter(RT == 3000) %>% summarise(N = length(Participant),
prop = N/112)
capture.output(as.matrix(missings_Adapt), as.matrix(missings_Bline), file = "output/Exp1_omissions_summary.txt")
#remove omissions from the data
E1_Adapt <- E1_Adapt %>% filter(RT != 3000) # 33
E1_Bline <- E1_Bline %>% filter(RT != 3000) # 4480
4480 - 4437
#save datasets again
save(E1_Bline, E1_Adapt, file ="input/Exp1_without_omissions.RData")
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
library("ez")
library("effectsize")
#library("ggplot2")
# load relevant functions
source("functions/mySummary.R")
source("functions/fitCumulativeGaussian.R")
#---------------------------------------------------------------------------------
#get the CG input data:
load(file ="input/Exp1_without_omissions.RData")
##################################################################
##average data across speaker and pseudoword (for Adaptation and Baselin block individually, and them combine the two)
CG_input <- mySummary(E1_Adapt, Resp, Participant, AdaptType, SpSex, tML) # Input for each participant, Adaptation Blocks
CG_input_BL <- mySummary(E1_Bline, Resp, Participant, Block, SpSex, tML) # Input for each participant, Baseline Blocks
CG_input_BL <- CG_input_BL %>% rename(AdaptType= Block)
CG_input <- rbind(CG_input, CG_input_BL)
rm(CG_input_BL)
View(CG_input)
## declare tML as numerical variable
CG_input$tML <- as.numeric(as.character(CG_input$tML))
#Fit a Cumulative Gaussian Function (CG) for each Subject x SpSex * AdaptType
CGdata <- myCGfit(CG_input, x = unique(CG_input$tML), Resp, Participant, AdaptType, SpSex)
### There were 102 warnings -> this happens when the algorithm tried to fit numbers that create a NaN in the pnorm()-command
warnings()
view(CGdata)
##################################################################
## plot values of the fits to identify outlier
summary(CGdata[,4:6]) # yep... some fits went wrong
#PSE - point of subjective equality
dotchart(CGdata$PSE)
hist(CGdata$PSE)
boxplot(CGdata$PSE)
#R2 - fit of the function
dotchart(CGdata$R2)
hist(CGdata$R2)
boxplot(CGdata$R2)
# inspect subjects that have a PSE > 80 and a R2 < 70
badFitR2 <- CGdata %>% filter(R2 < 0.6)
badFitPSE <- CGdata %>% filter(PSE > 80 | PSE < 20)
badFit <- rbind(badFitR2, badFitPSE)
unique(badFit$Participant) # 5 Subjects have bad fits and should be excluded in a second analysis
rm(badFitR2, badFitPSE)
###remove 4 participants with bad fit
CGdata <- CGdata %>% filter(!(Participant %in% badFit$Participant))
# now check again PSE values and R2
dotchart(CGdata$PSE) # all beautiful
dotchart(CGdata$R2)  # not all ideal, but acceptable
##create a new input variable, becaue we just have N=36 now
CG_input <- CG_input %>% filter(!(Participant %in% badFit$Participant))
CG_agg_input <- mySummary(CG_input, Resp, AdaptType, SpSex, tML) # Input averaged across all participant
## declare tML as numerical variable
CG_agg_input$tML <- as.numeric(as.character(CG_agg_input$tML))
#estimate the averaged cumulative gaussian
CGagg <- myCGfit(CG_agg_input, x = unique(CG_agg_input$tML), Resp, AdaptType, SpSex)
#save the datasets
save(CGagg, CGdata, CG_input, CG_agg_input, badFit, file="input/Exp1_CG_estimates.RData")
# clear directory
rm(list=ls())
#set working directory to current file
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
# load required packages
library("tidyverse")
library("ez")
library("effectsize")
library(lme4)           # version 1.1-35.1
library(ggeffects)      # version 1.6.0
library(afex)           # version 1.3-1
#library("ggplot2")
# load relevant functions
source("functions/mySummary.R")
source("functions/tracedEzOut.R")
#---------------------------------------------------------------------------------
#get the CG input data:
load(file ="input/Exp1_without_omissions.RData")
load(file ="input/Exp1_CG_estimates.RData")
#remove Baseline for data analysis
CGdata_Adapt <- CGdata %>% filter(AdaptType != "Baseline")
a<-ezANOVA(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, SpSex), type=3, detailed = TRUE)
b = tracedEzOut(a, print = TRUE, sph.cor = "HF", mau.p = 0.05, etasq = "partial", dfsep = ", ")
capture.output(b, file= "output/Exp1_CG_ANOVAI.txt")
# Daten visualisieren (just f)
ezPlot(data=CGdata_Adapt, dv=.(PSE), wid=.(Participant), within = .(AdaptType, SpSex), x=SpSex, split=AdaptType)
#aggregate Data (in this case not really necessary)
PH1 <- CGdata_Adapt %>% group_by(Participant, SpSex, AdaptType) %>% summarise(PSE = mean(PSE))
#get descriptive data
PH1_descriptive <- mySummary(PH1, PSE, SpSex, AdaptType)
#convert partly into wide format
PH1 <- spread(PH1, AdaptType, PSE)
### t-tests, separately for each SpSex
PH1f<- PH1 %>% filter(SpSex == "f")
AdaptType1 <- t.test(PH1f$`f_fea/m_ang`, PH1f$`f_ang/m_fea`, paired = TRUE)
PH1m<- PH1 %>% filter(SpSex == "m")
AdaptType2 <- t.test(PH1m$`f_fea/m_ang`, PH1m$`f_ang/m_fea`, paired = TRUE)
AdaptType1
AdaptType2
#save results
capture.output(as.matrix(PH1_descriptive), AdaptType1, AdaptType2, file = "output/Exp1_CG_post-hoc.txt")
#keep environment tidy
rm(PH1, PH1_descriptive, PH1f, PH1m, AdaptType1, AdaptType2, a, b)
rm(badFit, CG_agg_input, CG_input, CGagg, CGdata, CGdata_Adapt)
#aggregate across pseudoword, speaker and tML for analysis
E1_Resp <- mySummary(E1_Adapt, Resp, Participant, SpSex, AdaptType) #does not contain Baseline
a<-ezANOVA(data=E1_Resp, dv=.(Resp), wid=.(Participant), within = .(AdaptType, SpSex), type=3, detailed = TRUE)
b = tracedEzOut(a, print = TRUE, sph.cor = "HF", mau.p = 0.05, etasq = "partial", dfsep = ", ")
capture.output(b, file= "output/Exp1_Resp_ANOVAII.txt")
# Daten visualisieren (just f)
ezPlot(data=E1_Resp, dv=.(Resp), wid=.(Participant), within = .(AdaptType, SpSex), x=SpSex, split=AdaptType)
#aggregate Data (in this case not really necessary)
PH2 <- E1_Resp %>% group_by(Participant, SpSex, AdaptType) %>% summarise(Resp = mean(Resp))
#get descriptive data
PH2_descriptive <- mySummary(PH2, Resp, SpSex, AdaptType)
#convert partly into wide format
PH2 <- spread(PH2, AdaptType, Resp)
### t-tests, separately for each SpSex
PH2f<- PH2 %>% filter(SpSex == "f")
AdaptType1 <- t.test(PH2f$`f_fea/m_ang`, PH2f$`f_ang/m_fea`, paired = TRUE)
PH2m<- PH2 %>% filter(SpSex == "m")
AdaptType2 <- t.test(PH2m$`f_fea/m_ang`, PH2m$`f_ang/m_fea`, paired = TRUE)
AdaptType1
AdaptType2
#save results
capture.output(as.matrix(PH2_descriptive), AdaptType1, AdaptType2, file = "output/Exp1_Resp_post-hoc.txt")
#keep environment tidy
rm(PH2, PH2_descriptive, PH2f, PH2m, AdaptType1, AdaptType2)
#-------------------------------------------------------------------------------#
#                        Analysis 3: logistic regression                        #
#-------------------------------------------------------------------------------#
## declare tML as numerical variable
E1_Adapt$tML <- as.numeric(as.character(E1_Adapt$tML))
#scale tML, because this is recommended for mixed-effects modelling
E1_Adapt$tML_sc <- scale(E1_Adapt$tML)
# m: assumed fixed effects structure for SpID and Participant
m <- glmer(Resp ~ tML_sc * SpSex * AdaptType   + (1 | SpID) + (1 | Participant), data = E1_Adapt, family = binomial,
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))) # it was recommended to try out different optimizers to avoid converging failure and this worked
#------------------------------------------------------------------------
# Step2: calculating the p-values of the effects with afex
m_test<- mixed(m, data = E1_Adapt, method = "LRT", family = "binomial") # takes a few minutes
m_test
summary(m)
# save models as R objects
save(m, m_test, file= "input/E1_GLMs.RData")
# capture output of model "m"
capture.output(summary(m), m_test, file= "output/Exp1_GLMM.txt")
# extract fitted values
E1_Adapt$fitted <- fitted(m)
#aggregate values of fitted
GLM_fit <- mySummary(E1_Adapt, fitted, Participant, SpSex, AdaptType)
GLM_descriptive <- mySummary(GLM_fit, fitted, SpSex, AdaptType)
capture.output(GLM_descriptive, file= "output/Exp1_GLMM_descriptive.txt")
